<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Context Tree Weighting and Compression - meiji163</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="meiji163" />
  <meta name="description" content="In this post I go over the basics of data compression with arithmetic coding and describe the Context Tree Weighting algorithm. At the end I discuss implementation and some experimental results.
Information Theory Review First a quick review of information theory. Suppose that we receive some data \(x\) drawn from a discrete random variable \(X\), whose probability distribution is \(P\). Then the Shannon information content of \(x\) is defined as" />

  <meta name="keywords" content="meiji163, math, machine learning, programming" />






<meta name="generator" content="Hugo 0.89.4" />


<link rel="canonical" href="https://meiji163.github.io/post/context-tree-weighting/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">




<link rel="stylesheet" href="/css/center.css">


<meta property="og:title" content="Context Tree Weighting and Compression" />
<meta property="og:description" content="In this post I go over the basics of data compression with arithmetic coding and describe the Context Tree Weighting algorithm. At the end I discuss implementation and some experimental results.
Information Theory Review First a quick review of information theory. Suppose that we receive some data \(x\) drawn from a discrete random variable \(X\), whose probability distribution is \(P\). Then the Shannon information content of \(x\) is defined as" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://meiji163.github.io/post/context-tree-weighting/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-04-23T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-04-23T00:00:00+00:00" />

<meta itemprop="name" content="Context Tree Weighting and Compression">
<meta itemprop="description" content="In this post I go over the basics of data compression with arithmetic coding and describe the Context Tree Weighting algorithm. At the end I discuss implementation and some experimental results.
Information Theory Review First a quick review of information theory. Suppose that we receive some data \(x\) drawn from a discrete random variable \(X\), whose probability distribution is \(P\). Then the Shannon information content of \(x\) is defined as"><meta itemprop="datePublished" content="2021-04-23T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-04-23T00:00:00+00:00" />
<meta itemprop="wordCount" content="2496">
<meta itemprop="keywords" content="algorithms,compression,context tree weighting," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Context Tree Weighting and Compression"/>
<meta name="twitter:description" content="In this post I go over the basics of data compression with arithmetic coding and describe the Context Tree Weighting algorithm. At the end I discuss implementation and some experimental results.
Information Theory Review First a quick review of information theory. Suppose that we receive some data \(x\) drawn from a discrete random variable \(X\), whose probability distribution is \(P\). Then the Shannon information content of \(x\) is defined as"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">明治</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/">Home</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/post/">Archives</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/tags/">Tags</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/categories/">Categories</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/about/">About</a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      明治
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/">Home</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/post/">Archives</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/tags/">Tags</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/categories/">Categories</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://meiji163.github.io/about/">About</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">Context Tree Weighting and Compression</h1>
      
      <div class="post-meta">
        <time datetime="2021-04-23" class="post-time">
          2021-04-23
        </time>
        <div class="post-category">
            <a href="https://meiji163.github.io/categories/algorithms/"> algorithms </a>
            <a href="https://meiji163.github.io/categories/compression/"> compression </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#information-theory-review">Information Theory Review</a></li>
    <li><a href="#arithmetic-coding">Arithmetic Coding</a></li>
    <li><a href="#models">Models</a></li>
    <li><a href="#context-tree-weighting">Context Tree Weighting</a>
      <ul>
        <li><a href="#sidenote-compression--agi">Sidenote: Compression = AGI?</a></li>
        <li><a href="#ctw-extensions">CTW Extensions</a></li>
      </ul>
    </li>
    <li><a href="#implementation-and-experiments">Implementation and Experiments</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>In this post I go over the basics of data compression with arithmetic coding and describe the Context Tree Weighting algorithm. At the end I discuss implementation and some experimental results.</p>
<h2 id="information-theory-review">Information Theory Review</h2>
<p>First a quick review of information theory.
Suppose that we receive some data \(x\) drawn from a discrete random variable \(X\), whose probability distribution is \(P\). Then the Shannon information content of \(x\) is defined as</p>
<p>$$I(x) = -\log(P(x)).$$</p>
<p>Why is this a good measure of information? Basically, it formalizes the idea that less probable events yield more information, and conversely predictable events yield less information.</p>
<p>Given an incomplete message like <code>Hello Worl</code> you&rsquo;d assign a high probability (say 95%) that the next character is &ldquo;<em>d</em>&rdquo;. Finding out that the next character is indeed &ldquo;<em>d</em>&rdquo; would only give you about 0.07 units of information (also called shannons), since you in a sense already knew that.</p>
<p>The Shannon entropy is defined as the expected value of information $$H(X) = \sum_x -P(x)\log(P(x)).$$
It can be thought of as a measure of how predictable the data is on average.
Now suppose we want to compress a stream of data.<br>
Formally, we want a code \(C: \mathcal{A} \to \text{ \{0, 1\} } ^* \) where \(\mathcal{A}\) is the alphabet the data comes from (e.g. ASCII characters) and \(\text{\{0, 1\} }^*\) is the set of all binary strings. A good code should have two properties:</p>
<ul>
<li>\(C\) has an inverse (compression is lossless)</li>
<li>The codes \(C(x)\) have minimal average length (good compression ratio).</li>
</ul>
<p>Shannon proved that such an optimal code would have an average code length essentially <em>equal to the entropy</em> of the source.<br>
Moreover, he proved that for an optimal code, the code length \(\mid C(x) \mid\) would be <em>equal to the information content</em> \(I(x)\).  In other words, if we define the <em>redundancy</em> of our code \(C(x)\) as the difference \(\rho(x) = \mid C(x)\mid - I(x)\), then finding a good code is equivalent to minimizing the redundancy.<br>
Of course this is a bit sloppy; for more precise statements see e.g. <a href="#references">[2]</a></p>
<h2 id="arithmetic-coding">Arithmetic Coding</h2>
<p>Unsurprisingly, Shannon&rsquo;s proof is non-constructive, so how do we make an optimal code in practice? Several algorithms have been developed. You make have heard of the Huffman code or Lempel-Ziv algorithm, which one can prove are roughly optimal. Less commonly known is <em>arithmetic coding</em>.</p>
<p>The nice thing about arithmetic coding is you can plug in any probabilistic model \(\mathcal{M}\) of the source (i.e. a way to generate predictions for the next symbol) and it guarantees you a code length approximately equal to the entropy according to your model \(H(X \mid \mathcal{M})\). The idea is to associate each sequence to a subinterval of \([0,1)\), whose length is equal to its probability.</p>
<p>To illustrate the algorithm, suppose we are recieving a stream of binary data \(x_1,x_2,\dots,x_N\) (abbreviated \(x_1^N\)). Let \(L\) be the lower endpoint of the interval and \(U\) be the upper endpoint after receiving the \(n\)th symbol. Initially we have received no bits and set \(L=0\), \(U=1\).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">L, U ⟵ 0, <span class="m">1</span>
For <span class="nv">n</span> <span class="o">=</span> 1...N <span class="k">do</span>  
    generate prediction P<span class="o">(</span><span class="nv">xn</span> <span class="o">=</span> 0<span class="o">)</span>
        <span class="k">if</span> <span class="nv">xn</span> <span class="o">=</span> <span class="m">1</span>
            <span class="k">then</span> L ⟵ L +  P<span class="o">(</span><span class="nv">xn</span> <span class="o">=</span> 0<span class="o">)</span>*<span class="o">(</span>U-L<span class="o">)</span>
        <span class="k">else</span> <span class="nv">xn</span> <span class="o">=</span> <span class="m">0</span> and U ⟵ U-P<span class="o">(</span><span class="nv">xn</span> <span class="o">=</span> 1<span class="o">)</span>*<span class="o">(</span>U-L<span class="o">)</span>
        endif
endfor
</code></pre></div><p>At each step, we divide the current interval according to the probabilities of the next symbol. At the end, the compressed sequence is the sequence of binary digits of a number chosen from the interval \([L,U)\), (e.g. \(L\) rounded up).</p>
<p>After \(n\) steps there are \(2^n\) subintervals, corresponding to the possible sequences \(x_1&hellip;x_n\). For example after \(n=3\) the intervals might look like this:</p>

<link rel="stylesheet" href="/css/hugo-easy-gallery.css" />
<div class="box">
<figure  itemprop="associatedMedia"
  itemscope itemtype="http://schema.org/ImageObject" >
    <div class="img" data-size="900x400">
      <img itemprop="thumbnail" src="/images/coding.png#center" />
    </div>
    <a href="/images/coding.png#center" itemprop="contentUrl"></a>
  </figure>
</div>

<p>Note that the length of the intervals are \(P(x_1\dots x_n) = P(x_1^n)\). A trivial model that predicts \(P(x_1^n) = 2^{-n}\) would essentially give us back the original sequence (a terrible compressor indeed) &ndash; ideally our model assigns a larger probability to the sequence.</p>
<p>That interval is guaranteed to contain a rational number \(c\) with approximately \(-\log( P(x_1^n))\) digits in its binary expansion, reducing the number of bits needed to describe it. The encoder can end the message either with a special <code>EOT</code> symbol or by transmitting the length.</p>
<p>Given the code \(c\) and access to the same model \(\mathcal{M}\), the decoder can sequentially deduce whether the \(n\)th bit was a 0 or 1 by comparing \(c\) to the divider \(L + P(x_n = 0)\cdot(U-L)\) and hence uniquely decode the compressed data.</p>
<p>Arithmetic coding works the same way for non-binary alphabets, at each step dividing the interval into \(\mid\mathcal{A}\mid\) sections according to their probabilites.</p>
<h2 id="models">Models</h2>
<p>Assuming arithmetic coding can be implemented efficiently (see <a href="#implementation-and-experiments">below</a>), we have reduced compression to finding a good model of the data. Of course, the model will depend a lot on what type of data you&rsquo;re compressing and your speed/memory goals.</p>
<p>The simplest model could just use frequency counts of the different symbols to make predictions. If you wanted to go all out you could train a neural net like an RNN or <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer</a> on your data to make the predictions. However you&rsquo;d have to account for the size of the weights, which have to be sent the decoder. It would also be too slow for most purposes (although lightweight NN&rsquo;s <a href="http://mattmahoney.net/dc/mmahoney00.pdf">achieve reasonable speed</a>). Clearly there is a tradeoff between the complexity of the model and the compression ratio.</p>
<p>A simpler option is a <em>tree model</em>. We assume that \(P(x_n)\) depends on at most \(D\) of the previous symbols (in probability lingo, a \(D\)-Markov model).</p>
<p>The main idea is to build a suffix tree (or trie) from the source. Given past symbols \(x_{n-D},&hellip;,x_{n-1}\) (also known as the <em>context</em>) we take the last \(k \le D\) as the suffix. We are free to choose \(k\), and it can vary between contexts.   We then record the frequencies of each symbol we observe after seeing a suffix.</p>
<p>For example if the alphabet is \(\mathcal{A} = \text{ \{a ,b ,n\}}\) and the sequence &ldquo;\(\text{bananan}\)&rdquo; here is one possible depth \(D=2\) tree (suffixes are read from bottom up)</p>


<div class="box">
<figure  itemprop="associatedMedia"
  itemscope itemtype="http://schema.org/ImageObject" >
    <div class="img" data-size="1024x900">
      <img itemprop="thumbnail" src="/images/path12.png#center" alt="A 2-Markov Model"/>
    </div>
    <a href="/images/path12.png#center" itemprop="contentUrl"></a>
      <figcaption>
          <p>A 2-Markov Model</p>
      </figcaption>
  </figure>
</div>

<p>Each leaf has three counters (# \(\text{a}\)&rsquo;s, # \(\text{b}\)&rsquo;s , #\(\text{n}\)&rsquo;s). E.g. &ldquo;\(\text{n}\)&rdquo; appears two times after the suffix &ldquo;\(\text{na}\)&rdquo;. A tree like this is called a <em>prediction suffix tree</em> (PST). We can make rough estimates of the probability using the statistics stored in the leaves with e.g. a <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a>. Another common choice is the <a href="https://en.wikipedia.org/wiki/Krichevsky%E2%80%93Trofimov_estimator">Krichevsky-Trofimov estimator</a>.</p>
<p>A similar idea combined with the Lempel-Ziv algorithm forms the basis for the &ldquo;Prediction by Partial Matching&rdquo; algorithm, which is considered one of the top-performing tree models <a href="#references">[3]</a>.</p>
<h2 id="context-tree-weighting">Context Tree Weighting</h2>
<p>Context Tree Weighting (CTW) is a beautiful algorithm invented by Willems, Shtarkov, and Tjalkens <a href="#references">[1]</a> that efficiently computes a weighted sum over all prediction suffix trees of depth \(D\) for a binary alphabet. Naively, this would take \(O(2^D)\), while CTW computes it in \(O(D)\).</p>
<p>We first build a complete binary tree of depth \(D\), called the context tree. Like a prediction suffix tree, each node is labeled by its corresponding suffix \(s\). Each node stores the frequencies of 0&rsquo;s and 1&rsquo;s that occur after suffix \(s\), and computes a probability \(P^s\) recursively from its children as follows: Let \(x_1\dots x_n\) be the past symbols, then the probability stored at the node \(s\) is defined as</p>
<p>$$
P^s = \begin{cases}P_e(x_{1}^n) &amp; \text{ if } s \text{ is a leaf }\cr
\frac{1}{2}\left(P_e(x_{1}^n) + P^{s0}P^{s1}\right)&amp; \text{ otherwise.} \end{cases}
$$</p>
<p>Here \(P_e\) is a probability estimate based on the frequencies stored at \(s\) (in the original paper it is the <a href="https://en.wikipedia.org/wiki/Krichevsky%E2%80%93Trofimov_estimator">KT estimator</a>) and \(s0\), \(s1\) denote the children of \(s\).</p>
<p>So we just average the frequency estimate with the predictions of the children nodes. Simple, right? But what is the probability we get at the root node, corresponding to the empty suffix \(\epsilon\)? Brace for notation&hellip; it is</p>
<p>$$
P^{\epsilon} = \sum_{T \in \mathcal{M}_D}2^{-\Gamma_D(T)}P(x_1^n \mid T)
$$</p>
<p>where</p>
<ul>
<li>\(\mathcal{M}_D\) is the set of all PST&rsquo;s of depth at most \(D\)</li>
<li>\(P(x_1^n \mid T)\) is the probability of \(x_1\dots x_n\) according to the PST \(T\)</li>
<li>\(\Gamma_D(T)\) is the number of nodes of \(T\) minus the number of leaves at depth \(D\)</li>
</ul>
<p>Well we certainly have a weighted sum of PST predictions, but what is this \(\Gamma_D\)? It is actually the length of the optimal <a href="https://en.wikipedia.org/wiki/Prefix_code">prefix code</a> for the tree \(T\), i.e. the number of bits needed to describe \(T\). Thus each each prediction suffix tree is weighted by an Occam&rsquo;s razor-like penalty.</p>
<p>To make predictions with CTW we use the root probability, then update the path in the tree corresponding to the context when we receive the next symbol. The original paper proves a sharp bound on the redundancy of the code computed by CTW (Theorem 2).</p>
<h3 id="sidenote-compression--agi">Sidenote: Compression = AGI?</h3>
<p>Anyone into data compression probably knows about the <a href="http://prize.hutter1.net/">Hutter prize</a>, a cash prize for compressing the first GB of Wikipedia to smaller than the current record (116 MB). Hutter&rsquo;s slogan is &ldquo;Compression = AGI,&rdquo; a (rather exaggerated) summary of the principle behind <a href="https://en.wikipedia.org/wiki/AIXI">AIXI</a>.</p>
<p>Roughly speaking, AIXI solves the general reinforcement learning problem by weighing models of the environment by both the expected reward <em>and</em> a measure of the model&rsquo;s complexity. In particular, the complexity is measured by the <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogorov complexity</a> of the observation-reward sequence. (Hutter gives a fairly good non-technical explanation in <a href="https://www.youtube.com/watch?v=E1AxVXt2Gv4">this interview</a>).</p>
<p>Although theoretically optimal, the AIXI action function is infeasible to compute directly.<br>
What is so interesting about CTW is that the probability it computes is a mixture of models weighted by complexity (for a restricted set of models) <em>and</em> it is efficient to compute. For this reason Veness et. al [<a href="#references">5</a>] used CTW in their AIXI approximation algorithm. Other mixture models have also become popular in data compression algorithms (You can for example run several probability models in parallel).</p>
<h3 id="ctw-extensions">CTW Extensions</h3>
<p>The binary CTW can be extended to non-binary alphabets by replacing \(P^{s0}P^{s1}\) by a product over all children of \(s\) in the recursive formula. However the straightforward method of making direct predictions hasn&rsquo;t had much empirical success, especially with large alphabets.</p>
<p>In practice, CTW is good at making binary predictions, although it can still have non-binary contexts. How can we convert binary predictions to general symbol predictions?</p>
<p>The obvious way to do this is to first choose a binary code for the alphabet \(\mathcal{A}\), then predict each bit. This is the idea behind a &ldquo;decomposition tree,&rdquo; which is basically a binary search tree. The leaves of the tree are the elements of \(\mathcal{A}\), and each internal node has a context tree (a tree of trees) whose job is to predict whether a symbol is in the left or right subtree of the node.</p>
<p>The probability of a symbol \(a \in \mathcal{A}\) is then calculated as the product of the probabilities on the path from the root to the leaf \(a\).
For example, here is a possible decomposition tree for \(\mathcal{A} = \text{ \{b, a, n\}}\).</p>


<div class="box">
<figure  itemprop="associatedMedia"
  itemscope itemtype="http://schema.org/ImageObject" 
  style="max-width:450" >
    <div class="img">
      <img itemprop="thumbnail" src="/images/ctw.png#center" alt="A decomposition tree with two context trees"/>
    </div>
    <a href="/images/ctw.png#center" itemprop="contentUrl"></a>
      <figcaption>
          <p>A decomposition tree with two context trees</p>
      </figcaption>
  </figure>
</div>

<p>Context Tree 1 predicts whether the next symbol will be \(\text{b}\) or not, and context tree 2 decides between \(\text{a}\) and \(\text{n}\).</p>
<p>One drawback of this approach is that the performance is sensitive to the topology of the decomposition tree. One choice is <a href="https://en.wikipedia.org/wiki/Huffman_coding">the Huffman tree</a>, which minimizes the number of context trees updates that are required.</p>
<p>In general we want to find groupings of the symbols which are &ldquo;similar,&rdquo; in some way. We could for example collect statistics on co-occurence of symbols à la <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>. Once we decide on a decomposition tree, we have to describe it to the decompressor, but this is only a few more bytes overhead.</p>
<h2 id="implementation-and-experiments">Implementation and Experiments</h2>
<p>To experiment I wrote a <a href="https://github.com/meiji163/ctwz">simple implementation</a> of CTW using a Huffman decomposition tree.</p>
<p>The main difficulty in implementation is the precision of the probabilities. The original form of the arithmetic encoder requires arbitrary precision. To make it practical we can use finite precision and output a bit once the leading bits of \(U\) and \(L\) are equal. Then we scale the whole interval by \(2\). A more clever version of this scaling was invented by Witten, Neal, and Cleary <a href="#references">[6]</a>, which is the version I used.</p>
<p>The original CTW algorithm also needs modification. The main technique is to store a ratio of probabilities in the nodes to handle float-point errors. The exact method I used is the one described in <a href="#references">[4]</a>.</p>
<p>I tested my implementation with depth \(D=12\) on some text data from the <a href="https://www.corpus.canterbury.ac.nz/">Canterbury corpus</a>. For comparison I also compressed the files with Unix&rsquo;s &ldquo;compress&rdquo; and gzip on default settings. Both use variants of the Lempel-Ziv algorithm.</p>
<table>
<thead>
<tr>
<th style="text-align:center">File</th>
<th style="text-align:center">Size (Bytes)</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">grammar.lsp</td>
<td style="text-align:center">3721</td>
<td style="text-align:center">LISP code</td>
</tr>
<tr>
<td style="text-align:center">fields.c</td>
<td style="text-align:center">11150</td>
<td style="text-align:center">C code</td>
</tr>
<tr>
<td style="text-align:center">plrabn12.txt</td>
<td style="text-align:center">481861</td>
<td style="text-align:center">Milton&rsquo;s Paradise Lost</td>
</tr>
<tr>
<td style="text-align:center">bible.txt</td>
<td style="text-align:center">4047392</td>
<td style="text-align:center">King James Bible</td>
</tr>
<tr>
<td style="text-align:center">E.coli</td>
<td style="text-align:center">4638690</td>
<td style="text-align:center">Genome of E.Coli</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Compression Ratio</th>
<th style="text-align:center">ctw</th>
<th style="text-align:center">compress</th>
<th style="text-align:center">gzip</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">fields.c</td>
<td style="text-align:center">4.21</td>
<td style="text-align:center">2.24</td>
<td style="text-align:center">3.55</td>
</tr>
<tr>
<td style="text-align:center">grammar.lsp</td>
<td style="text-align:center">3.65</td>
<td style="text-align:center">2.05</td>
<td style="text-align:center">2.99</td>
</tr>
<tr>
<td style="text-align:center">plrabn12.txt</td>
<td style="text-align:center">3.15</td>
<td style="text-align:center">2.37</td>
<td style="text-align:center">2.48</td>
</tr>
<tr>
<td style="text-align:center">bible.txt</td>
<td style="text-align:center">4.50</td>
<td style="text-align:center">3.39</td>
<td style="text-align:center">3.39</td>
</tr>
<tr>
<td style="text-align:center">E.coli</td>
<td style="text-align:center">4.09</td>
<td style="text-align:center">3.69</td>
<td style="text-align:center">3.56</td>
</tr>
</tbody>
</table>
<p>It is interesting to look at the predictions CTW makes. It is particularly good at detecting basic structure like spaces between words, braces, parenthesis, etc. and repeated words and phrases. For example in fields.c consistently predicts ( \(p \approx 0.8\)) that function declarations like <code>realloc ()</code> are followed by <code>;</code> and that comments starting with <code>/*</code> end with <code>*/</code>.</p>
<p>In <code>bible.txt</code>, it is particularly good at predicting common words like &ldquo;God&rdquo; (big surprise). The probabilities for E.coli are actually rarely greater than \(0.3\). Since \(\mathcal{A} = \text{\{g, c, t, a\}}\) , the compression in this case is mainly due to the fact that the alphabet is small.</p>
<p>We can see CTW is basically finding the &ldquo;low hanging fruit&rdquo; of redundancy. This is about all we can expect, since we know Markov models aren&rsquo;t particularly good at learning grammatical structures.</p>
<p>Although CTW compares favorably on these text files, my implementation failed miserably when I tried it on binary data (possible due to my janky code). My implementation is also 5-10 times slower than gzip and compress on large files, and undoubtedly uses much more memory.</p>
<p>The good news is there is a lot of room for improvement. Obvious optimizations would be parallelizing the context trees and using fixed-point arithmetic instead of doubles. I highly recommend Volf&rsquo;s thesis <a href="#references">[4]</a>, in which he documents his CTW compressor project in great detail. He uses the previously mentioned optimizations (and many more) to satisfy a memory limit of 32MB and a compression speed of around 10kB/s.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Context Tree Weighting is a beautiful example of a mixture model with &ldquo;Occam&rsquo;s-Razor&rdquo; weighting. Its solid theoretical foundations make it attractive compared to e.g. Prediction by Partial Matching. However it is trickier to implement because of greater memory and computational requirements.</p>
<h2 id="references">References</h2>
<p><a href="https://www.cs.cmu.edu/~aarti/Class/10704_Spring15/CTW.pdf">[1]</a> Willems, Shtarkov, Tjalkens &ldquo;<em>The Context-Tree Weighting Method: Basic Properties</em>&rdquo; 1995</p>
<p><a href="https://web.cs.iastate.edu/~honavar/infotheorybook.pdf">[2]</a> D. MacKay, &ldquo;<em>Information Theory, Inference, and Learning Algorithms</em>&rdquo; 2003</p>
<p><a href="https://www.jair.org/index.php/jair/article/view/10394">[3]</a> Begleiter, El-Yaniv, Yona, &ldquo;<em>On Prediction Using Variable Order Markov Models</em>&rdquo; 2004</p>
<p><a href="https://pure.tue.nl/ws/files/2043425/200213835.pdf">[4]</a> P. Volf, &ldquo;<em>Weighting techniques in data compression: theory and algorithms</em>&rdquo; 2002</p>
<p><a href="https://www.aaai.org/Papers/JAIR/Vol40/JAIR-4004.pdf">[5]</a> Veness, Siong Ng, Hutter, Uther, Silver &ldquo;<em>A Monte-Carlo AIXI Approximation</em>&rdquo; 2011</p>
<p><a href="https://dl.acm.org/doi/10.1145/214762.214771">[6]</a> Witten, Neal, Cleary &ldquo;<em>Arithmetic Coding for Data Compression</em>&rdquo; 1987</p>

    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">meiji163</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
      2021-04-23
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>


    
    

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://meiji163.github.io/tags/algorithms/">algorithms</a>
          <a href="https://meiji163.github.io/tags/compression/">compression</a>
          <a href="https://meiji163.github.io/tags/context-tree-weighting/">context tree weighting</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/gh-extension/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">Fun With GitHub CLI Extensions</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/sum-of-squares/">
            <span class="next-text nav-default">Fast Sum of Two Squares Algorithm</span>
            <span class="prev-text nav-mobile">Next</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:mysatellite99@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://math.stackexchange.com/users/201018/mysatellite" rel="me noopener" class="iconfont"
      title="stack-overflow"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M809.714286 932.571429l-638.857143 0 0-274.285714-91.428571 0 0 365.714286 821.714286 0 0-365.714286-91.428571 0 0 274.285714zm-538.285714-299.428571l18.857143-89.714286 447.428571 94.285714-18.857143 89.142857zm58.857143-213.714286l38.285714-83.428571 414.285714 193.714286-38.285714 82.857143zm114.857143-203.428571l58.285714-70.285714 350.857143 293.142857-58.285714 70.285714zm226.857143-216l272.571429 366.285714-73.142857 54.857143-272.571429-366.285714zm-410.285714 840.571429l0-90.857143 457.142857 0 0 90.857143-457.142857 0z"></path>
</svg>

    </a>
  
    <a href="https://github.com/meiji163" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://codeforces.com/profile/meiji163" rel="me noopener" class="iconfont"
      title="codeforces"  target="_blank"
      >
      <svg width="36" height="36" class="icon" style="" version="1.1" viewBox="0 0 1024 1024">
<path d="M 192 334.2 C 227.3 334.2 256 369.2 256 412.4 v 547.5 C 256 1003.2 227.3 1038.2 192 1038.2 H 64 C 28.7 1038.2 0 1003.2 0 960 V 412.4 C 0 369.2 28.7 334.2 64 334.2 h 128 z m 384 -234.7 C 611.3 99.6 640 134.5 640 177.8 v 782.2 C 640 1003.2 611.3 1038.2 576 1038.2 H 448 C 412.7 1038.2 384 1003.2 384 960 V 177.8 C 384 134.5 412.7 99.6 448 99.6 h 128 z m 384 391.1 C 995.3 490.6 1024 525.7 1024 568.9 v 391.1 C 1024 1003.2 995.3 1038.2 960 1038.2 h -128 C 796.7 1038.2 768 1003.2 768 960 V 568.9 C 768 525.7 796.7 490.6 832 490.6 h 128 z" />
</svg>

    </a>
  
    <a href="https://qoto.org/@meiji163" rel="me noopener" class="iconfont"
      title="mastodon"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 448 512" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36"><path fill="currentColor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"></path></svg>
    </a>


<a href="https://meiji163.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2021
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        meiji163
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>






  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css"
    integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG"
    crossorigin="anonymous">

  
  <script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js"
    integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1"
    crossorigin="anonymous"></script>

  
  <script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous" onload="renderMathInElement(document.body);">
  </script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        
      });
    });
  </script>






  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  









  <script id="dsq-count-scr" src="//.disqus.com/count.js" async></script>







</body>
</html>
